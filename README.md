ğŸ–ï¸ NoMouse â€“ Control Your Computer Using Hand Gestures

A computer visionâ€“based virtual mouse system that allows users to control the mouse cursor using hand gestures captured through a webcam. This project eliminates the need for a physical mouse by leveraging Python, OpenCV, and MediaPipe.

ğŸ“Œ Project Overview

NoMouse tracks hand landmarks in real time and maps specific hand gestures to mouse actions such as:

Cursor movement

Left click

Right click

Scrolling

Drag and drop

This project is useful for:

Touch-free computer interaction

Accessibility solutions

Humanâ€“Computer Interaction (HCI) research

Learning computer vision and gesture recognition

ğŸš€ Features

âœ” Real-time hand detection
âœ” Smooth mouse cursor movement
âœ” Left & right mouse click using gestures
âœ” Scroll up & down using hand motion
âœ” Drag and drop functionality
âœ” Platform-independent (Windows / Linux / macOS)

ğŸ› ï¸ Technologies Used

Python 3

OpenCV â€“ image processing

MediaPipe â€“ hand landmark detection

NumPy â€“ numerical operations

PyAutoGUI / Pynput â€“ mouse & keyboard control

ğŸ“‚ Project Structure
NoMouse/
â”‚
â”œâ”€â”€ main.py                 # Main application file
â”œâ”€â”€ hand_tracking.py        # Hand detection & landmark tracking
â”œâ”€â”€ mouse_controller.py     # Mouse control logic
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # Project documentation
â””â”€â”€ assets/                 # Images / demo screenshots

ğŸ§‘â€ğŸ’» Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/NoMouse.git
cd NoMouse

2ï¸âƒ£ Create a Virtual Environment (Optional but Recommended)
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


requirements.txt

opencv-python
mediapipe
numpy
pyautogui
pynput

â–¶ï¸ How to Run
python main.py


ğŸ“· Make sure your webcam is connected and working.

âœ‹ Gesture Controls
Gesture	Action
Index finger up	Move mouse
Index + Thumb close	Left click
Middle + Thumb close	Right click
Two fingers up	Scroll
Fist	Drag
Open palm	Release drag

(Gestures can be customized in the code)

âš™ï¸ How It Works

Webcam captures live video frames

MediaPipe detects 21 hand landmarks

Finger positions are analyzed

Gestures are recognized based on distances and angles

Mouse actions are executed using PyAutoGUI / Pynput

ğŸ“¸ Demo

Add screenshots or a GIF here to showcase the working project.

assets/demo.gif

âš ï¸ Limitations

Requires good lighting conditions

Performance depends on webcam quality

Background clutter may affect accuracy

Slight delay on low-end systems

ğŸ”® Future Enhancements

Multi-hand support

Gesture customization UI

AI-based gesture learning

Mobile camera support

Voice + gesture hybrid control

ğŸ“š Learning Outcomes

Computer Vision fundamentals

Hand landmark detection

Gesture recognition logic

Human-Computer Interaction (HCI) concepts

Real-time system development

ğŸ‘¤ Author

Abdus Salam
Android Developer â€¢ Python Enthusiast â€¢ UI Explorer
